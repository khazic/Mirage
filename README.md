# Mmoment
Multi-Modal Modeling and Evaluation on Novel Tasks

## 介绍
本项目旨在评估和改进大型视觉语言模型（LVLM）在多模态任务中的表现。我们针对不同场景设计了一系列基准测试，以识别模型在处理复杂任务时的优势和不足。

## 基准测试场景

### 1. 否定描述的准确性问题
- **目的**：评估模型在处理否定样本时的准确性，识别其在判断不存在内容时的局限性。

### 2. 多实体召回问题
- **目的**：测试模型在多物体场景中的召回能力，分析其对主要和次要物体的识别能力。

### 3. 程度理解问题
- **目的**：评估模型对物体相对属性的判断能力，探索其在主观评判标准下的表现。

### 4. 位置信息理解问题
- **目的**：分析模型对绝对和相对位置信息的理解能力，识别其在空间关系判断中的不足。

### 5. 视频时序判断问题
- **目的**：测试模型在视频场景中定位特定时间点的能力，评估其对时序信息的理解。

### 6. 标志性识别问题
- **目的**：评估模型对品牌标志和知名人物的识别能力，分析其在特定文化符号理解上的表现。

### 7. 指令跟随能力
- **目的**：测试模型在执行特定指令时的准确性，评估其遵循指令约束的能力。

### 8. 计数能力
- **目的**：评估模型在不同复杂度场景下的计数准确性，分析其在简单与复杂场景中的表现差异。

### 9. 复杂图表信息提取
- **目的**：测试模型对结构化信息的理解和提取能力，评估其在处理复杂数据格式时的表现。

## 任务设计
针对上述每个场景，我们将设计不同难度的任务（easy/hard），以全面评估模型在多模态任务中的表现和改进空间。
